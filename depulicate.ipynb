{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import jieba\n",
    "import pickle\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********start 2020-09-23 14:39:00 ***********\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "print(starttime.strftime('***********start %Y-%m-%d %H:%M:%S ***********'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('E:/workspace/simhash/data/test5.pickle', mode='rb') as file:\n",
    "    wordfreq = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_words(df, title, content):\n",
    "    wordList = []\n",
    "    text = str(df[title])+','+str(df[content])\n",
    "    sentence_seged = jieba.lcut(text)\n",
    "    #sentence_seged = pseg.cut(text)\n",
    "    rule = '[^/.0-9a-zA-Z\\u4e00-\\u9fa5]+'\n",
    "    for x in sentence_seged:\n",
    "        word = re.sub(rule, '', x)\n",
    "        if word:\n",
    "            wordList.append(word)\n",
    "    return ' '.join(wordList[:int(len(wordList)*0.8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text_words):\n",
    "    features = text_words.split(' ')\n",
    "    v = np.array([0] * 64)\n",
    "    i = 0\n",
    "    for f in features:\n",
    "        if f in wordfreq\n",
    "            v = v + wordfreq[f]\n",
    "            i = i + 1\n",
    "    return v/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def hashfunc(x):\n",
    "    return int(hashlib.md5(x).hexdigest(), 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text_words):\n",
    "    features = text_words.split(' ')\n",
    "    v = [0] * 64\n",
    "    truncate_mask = 2**64 - 1\n",
    "    bitstring_format = '0{}b'.format(64)\n",
    "    for f in features:\n",
    "        h = hashfunc(f.encode('utf-8'))\n",
    "        h_bits = format(h & truncate_mask, bitstring_format)\n",
    "        v = [x + (1 if bit == \"1\" else -1) for bit, x in zip(h_bits, v)]\n",
    "#     binary_str = ''.join('0' if i <= 0 else '1' for i in v)\n",
    "    return [0 if i <= 0 else 1 for i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "nwidth = 4\n",
    "width = math.ceil(64/nwidth)\n",
    "def bit_vec(row):\n",
    "    vec = [ '0' if i <= 0 else '1' for i in row['vec']]\n",
    "    return tuple([''.join(vec[i*width:i*width+width]) for i in range(nwidth)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle_data = pd.read_excel('C:/Users/yangwenbin/Downloads/query-hive-48357.xlsx', usecols = 'C, H, N, P, Q')\n",
    "# handle_data.rename(columns={'info_browser_tmp_sea.news_id':'news_id', 'info_browser_tmp_sea.title':'title',\n",
    "#                             'info_browser_tmp_sea.news_tag':'news_tag', 'info_browser_tmp_sea.type':'type',\n",
    "#                             'info_browser_tmp_sea.content':'content'}, inplace = True)\n",
    "handle_data['text_words'] = handle_data.apply(split_words, axis=1, args=('title', 'content'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data = handle_data[handle_data['text_words'] != '']\n",
    "title_data['vec'] = title_data['text_words'].apply(vectorize_text)\n",
    "title_data[['vec0','vec1','vec2','vec3']] = title_data.apply(bit_vec, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq0 = dict()\n",
    "wordfreq1 = dict()\n",
    "wordfreq2 = dict()\n",
    "wordfreq3 = dict()\n",
    "for tup in zip(title_data['vec0'], title_data['vec1'], title_data['vec2'], title_data['vec3'], title_data['news_id']):\n",
    "    hash_str = ''.join(tup[:-1])\n",
    "    if tup[0] not in wordfreq0:\n",
    "        wordfreq0[tup[0]] = []\n",
    "    wordfreq0[tup[0]].append((hash_str, tup[-1]))\n",
    "    if tup[1] not in wordfreq1:\n",
    "        wordfreq1[tup[1]] = []\n",
    "    wordfreq1[tup[1]].append((hash_str, tup[-1]))\n",
    "    if tup[2] not in wordfreq2:\n",
    "        wordfreq2[tup[2]] = []\n",
    "    wordfreq2[tup[2]].append((hash_str, tup[-1]))\n",
    "    if tup[3] not in wordfreq3:\n",
    "        wordfreq3[tup[3]] = []\n",
    "    wordfreq3[tup[3]].append((hash_str, tup[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(one, two):\n",
    "    one = int(one, 2)\n",
    "    two = int(two, 2)\n",
    "    x = (one ^ two) & ((1 << 64) - 1)\n",
    "    ans = 0\n",
    "    while x:\n",
    "        ans += 1\n",
    "        x &= x - 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = locals()\n",
    "def simlar(row, i):\n",
    "#     if i == 0:\n",
    "#         wordfreqi = wordfreq0\n",
    "#     elif i == 1:\n",
    "#         wordfreqi = wordfreq1\n",
    "#     elif i == 2:\n",
    "#         wordfreqi = wordfreq2\n",
    "#     else:\n",
    "#         wordfreqi = wordfreq3\n",
    "    wordfreqi = names['wordfreq'+str(i)]\n",
    "#     exec('wordfreqi = wordfreq{}'.format(i))\n",
    "    if len(wordfreqi[row['vec'+str(i)]]) > 1:\n",
    "        hash_id_s = wordfreqi[row['vec'+str(i)]]\n",
    "        hash_str = ''.join((row['vec0'], row['vec1'], row['vec2'], row['vec3']))\n",
    "        for hash_id in hash_id_s:\n",
    "            if row['news_id'] < hash_id[-1]:\n",
    "                if distance(hash_str, hash_id[0]) <= 3:\n",
    "                    return hash_id[-1]\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35161, 12)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_data[title_data['iskeep'] == True].shape\n",
    "# [['news_id', 'title', 'iskeep']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iskeep(row):\n",
    "    simlarid = simlar(row, 0)\n",
    "    if simlarid:\n",
    "        return simlarid\n",
    "    else:\n",
    "        simlarid = simlar(row, 1)\n",
    "        if simlarid:\n",
    "            return simlarid\n",
    "        else:\n",
    "            simlarid = simlar(row, 2)\n",
    "            if simlarid:\n",
    "                return simlarid\n",
    "            else:\n",
    "                simlarid = simlar(row, 3)\n",
    "                if simlarid:\n",
    "                    return simlarid\n",
    "                else:\n",
    "                    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********start 2020-09-24 09:52:19 ***********\n"
     ]
    }
   ],
   "source": [
    "starttime = datetime.datetime.now()\n",
    "print(starttime.strftime('***********start %Y-%m-%d %H:%M:%S ***********'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data['iskeep'] = title_data.apply(iskeep, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********stop 2020-09-24 09:55:40 ***********\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "endtime = datetime.datetime.now()\n",
    "print(endtime.strftime('***********stop %Y-%m-%d %H:%M:%S ***********'))\n",
    "print((endtime - starttime).seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     if len(wordfreq0[row['vec0']]) > 1:\n",
    "#         hash_id_s = wordfreq0[row['vec0']]\n",
    "#         for hash_id in hash_id_s:\n",
    "#             if row['news_id'] != hash_id[-1]:\n",
    "#                 hash_str = ''.join((row['vec0'], row['vec1'], row['vec2'], row['vec3'))\n",
    "#                 if distance(hash_str, hash_id[0]) <= 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-09-24'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "time.strftime('%Y-%m-%d', time.localtime(time.time() - 3600 * 1 * 25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
